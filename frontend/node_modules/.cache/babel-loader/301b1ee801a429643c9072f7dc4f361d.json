{"ast":null,"code":"import _classCallCheck from \"C:/Users/RajaJ/Downloads/YogaIntelliJ-main/YogaIntelliJ-main/frontend/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { useShapeUniforms } from './gpgpu_math';\nexport var DepthwiseConvPacked2DProgram = function DepthwiseConvPacked2DProgram(convInfo) {\n  var addBias = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  var activation = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n  var hasPreluActivation = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  var hasLeakyReluAlpha = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n\n  _classCallCheck(this, DepthwiseConvPacked2DProgram);\n\n  this.variableNames = ['x', 'W'];\n  this.packedInputs = true;\n  this.packedOutput = true;\n  this.customUniforms = [{\n    name: 'pads',\n    type: 'ivec2'\n  }, {\n    name: 'strides',\n    type: 'ivec2'\n  }, {\n    name: 'dilations',\n    type: 'ivec2'\n  }, {\n    name: 'inDims',\n    type: 'ivec2'\n  }];\n  this.outputShape = convInfo.outShape;\n  this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);\n  var channelMul = convInfo.outChannels / convInfo.inChannels;\n  var padLeft = convInfo.padInfo.left;\n  var strideWidth = convInfo.strideWidth;\n  var dilationWidth = convInfo.dilationWidth;\n  var filterHeight = convInfo.filterHeight;\n  var filterWidth = convInfo.filterWidth;\n  var texelsAcross = filterWidth;\n  var mainLoop = \"\\n      int xR; int xC; int xCOffset;\\n      vec4 wTexel; vec4 previous; vec4 final;\";\n\n  for (var c = 0; c < filterWidth; c++) {\n    mainLoop += \"\\n          vec4 xTexelC\".concat(c * 2, \";\\n          int xTexelC\").concat(c * 2, \"Ready;\\n          vec4 xTexelC\").concat(c * 2 + 1, \";\\n          int xTexelC\").concat(c * 2 + 1, \"Ready;\\n          vec4 xC\").concat(c, \";\");\n  }\n  /**\n   * This vectorized implementation works by gathering the values needed for\n   * each output channel's dot product into vec4's and then multiplying them\n   * all together (this happens in the final double for-loop below). Most of\n   * the main loop consists of constructing these vec4's with the minimum\n   * number of texture2D calls, which means making use of all four returned\n   * values from a texture2D call at once.\n   */\n\n\n  mainLoop += \"\\n    for (int r = 0; r < \".concat(filterHeight, \"; r++) {\\n      \");\n\n  for (var _c = 0; _c < filterWidth; _c++) {\n    mainLoop += \"\\n          xTexelC\".concat(_c * 2, \" = vec4(0.0);\\n          xTexelC\").concat(_c * 2, \"Ready = 0;\\n          xTexelC\").concat(_c * 2 + 1, \" = vec4(0.0);\\n          xTexelC\").concat(_c * 2 + 1, \"Ready = 0;\\n          xC\").concat(_c, \" = vec4(0.0);\");\n  }\n\n  mainLoop += \"\\n        xR = xRCorner + r * dilations[0];\\n        if (xR >=0 && xR < inDims[0]) {\\n      \";\n\n  for (var texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n    var colIndex = texelC * 2;\n    mainLoop += \"\\n          xC = xCCorner + \".concat(colIndex * dilationWidth, \";\\n          \");\n\n    if (strideWidth === 1) {\n      if (colIndex < filterWidth) {\n        // If padding is odd, the outer texels have to be composed.\n        if (padLeft % 2 === 1) {\n          // TODO: Ensure vec4 previous does not result in redundant sample,\n          // and avoid setting xTexelRC's that exceed the boundary in the\n          // first place rather than resetting them to vec4(0)).\n          // To compute xCOffset:\n          // - If padding is odd, we must add 1 to ensure we ask for an\n          // even-numbered row.\n          // - We subtract 2 to access the previous texel.\n          mainLoop += \"\\n                xCOffset = xC + 1;\\n                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex, \" = getX(batch, xR, xCOffset, d1);\\n\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex, \"Ready = 1;\\n                }\\n              \"); // This texel has been read in previous iteration if the dilation\n          // is 1.\n\n          if (dilationWidth === 1 && colIndex > 0) {\n            mainLoop += \"\\n                xC\".concat(colIndex, \" = vec4(xTexelC\").concat(colIndex - 2, \".zw, xTexelC\").concat(colIndex, \".xy);\\n                \");\n          } else {\n            mainLoop += \"\\n                  xCOffset = xC + 1 - 2;\\n\\n                  if (xCOffset >= 0 && xCOffset < inDims[1]) {\\n                    previous = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= inDims[1]) {\\n                      previous.zw = vec2(0.0);\\n                    }\\n\\n                    xC\".concat(colIndex, \" = vec4(previous.zw, xTexelC\").concat(colIndex, \".xy);\\n                  } else {\\n                    xC\").concat(colIndex, \" = vec4(0.0, 0.0, xTexelC\").concat(colIndex, \".xy);\\n                  }\\n                  \");\n          }\n        } else {\n          // Padding is even, so xRC corresponds to a single texel.\n          mainLoop += \"\\n                if (xC >= 0 && xC < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = xTexelC\").concat(colIndex, \";\\n                \");\n        }\n\n        if (colIndex + 1 < filterWidth) {\n          // If dilation is even, the second entry should match the first\n          // (either both are composed or both are single samples). But if\n          // dilation is odd, then the second entry should be the opposite\n          // of the first (if the first is composed, the second is a single\n          // sample, and vice versa.)\n          var nextTexelOffset = padLeft % 2 === 0 ? util.nearestLargerEven(dilationWidth) : dilationWidth;\n\n          if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {\n            mainLoop += \"\\n                  xCOffset = xC + imod(pads[1], 2) + \".concat(nextTexelOffset, \";\\n\\n                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                    xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= inDims[1]) {\\n                      xTexelC\").concat(colIndex + 1, \".zw = vec2(0.0);\\n                    }\\n                    xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                  }\\n                  \"); // If dilation > 1 then the xRC's will not be able to share any\n            // values, so each xRC will require two unique calls to getX.\n\n            if (dilationWidth > 1) {\n              mainLoop += \"\\n                    xCOffset -= 2;\\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                      xTexelC\").concat(colIndex, \" = getX(batch, xR, xCOffset, d1);\\n                      xTexelC\").concat(colIndex, \"Ready = 1;\\n                    }\\n                    \");\n            }\n\n            mainLoop += \"\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(colIndex, \".zw, xTexelC\").concat(colIndex + 1, \".xy);\\n                  \");\n          } else {\n            // If dilation is 1 and padding is odd, we have already read the\n            // texel when constructing the previous x value. Here we can\n            // simply skip the texture read.\n            if (nextTexelOffset === 1) {\n              mainLoop += \"\\n                    xC\".concat(colIndex + 1, \" = xTexelC\").concat(colIndex, \";\\n                    \");\n            } else {\n              mainLoop += \"\\n                    xCOffset = xC + \".concat(nextTexelOffset, \";\\n\\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                      xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xCOffset, d1);\\n                      if (xCOffset + 1 >= inDims[1]) {\\n                        xTexelC\").concat(colIndex + 1, \".zw = vec2(0.0);\\n                      }\\n                      xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                    }\\n\\n                    xC\").concat(colIndex + 1, \" = xTexelC\").concat(colIndex + 1, \";\\n                    \");\n            }\n          }\n        }\n      }\n    } else {\n      // stride === 2\n      if (colIndex < filterWidth) {\n        // Depending on whether padLeft is even or odd, we want either the\n        // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n        // even, xC${colIndex +1} is simply the zw channels of texels we've\n        // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n        // need to come from the xy channels of a new texel, hence the `\n        // vec4\n        // final` initialized below.\n        if (padLeft % 2 === 1) {\n          mainLoop += \"\\n                xCOffset = xC + 1 - strides[1];\\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex, \" = getX(batch, xR, xCOffset, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex, \"Ready = 1;\\n                }\\n\\n                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xC + 1, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xC + 2 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex + 1, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = vec4(xTexelC\").concat(colIndex, \".zw, xTexelC\").concat(colIndex + 1, \".zw);\\n              \");\n\n          if (colIndex + 1 < filterWidth) {\n            mainLoop += \"\\n                  final = vec4(0.0);\\n                  xCOffset = xC + 1 + strides[1];\\n                  if(xCOffset >= 0 && xCOffset < inDims[1]) {\\n                    final = getX(batch, xR, xCOffset, d1);\\n                  }\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(colIndex + 1, \".xy, final.xy);\\n                \");\n          }\n        } else {\n          mainLoop += \"\\n                if(xC >= 0 && xC < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex, \"Ready = 1;\\n                }\\n\\n                xCOffset = xC + strides[1];\\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xCOffset, d1);\\n                  if (xCOffset + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex + 1, \".zw = vec2(0.);\\n                  }\\n                  xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = vec4(\\n                  xTexelC\").concat(colIndex, \".xy, xTexelC\").concat(colIndex + 1, \".xy);\\n              \");\n\n          if (colIndex + 1 < filterWidth) {\n            mainLoop += \"\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(colIndex, \".zw, xTexelC\").concat(colIndex + 1, \".zw);\\n                \");\n          }\n        }\n      }\n    } // localize the dotProd accumulation within the loop, the theory is for\n    // GPU with limited cache, accumulate sum across large amount of\n    // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n    // 50 variables)\n\n\n    if (colIndex < filterWidth) {\n      mainLoop += \"\\n            wTexel = getW(r, \".concat(colIndex, \", d1, q);\\n            dotProd += xC\").concat(colIndex, \" * vec4(wTexel.xz, wTexel.xz);\\n          \");\n\n      if (colIndex + 1 < filterWidth) {\n        mainLoop += \"\\n              wTexel = getW(r, \".concat(colIndex + 1, \", d1, q);\\n              dotProd += xC\").concat(colIndex + 1, \" * vec4(wTexel.xz, wTexel.xz);\\n            \");\n      }\n    }\n  }\n\n  mainLoop += \"\\n    }\\n  \";\n  mainLoop += \"\\n      }\\n    \";\n  var activationSnippet = '',\n      applyActivationSnippet = '';\n\n  if (activation) {\n    if (hasPreluActivation) {\n      activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(activation, \"\\n        }\");\n    } else if (hasLeakyReluAlpha) {\n      activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(activation, \"\\n        }\");\n    } else {\n      activationSnippet = \"vec4 activation(vec4 x) {\\n          \".concat(activation, \"\\n        }\");\n    }\n\n    applyActivationSnippet = \"result = activation(result);\";\n  }\n\n  var addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n\n  if (addBias) {\n    this.variableNames.push('bias');\n  }\n\n  if (hasPreluActivation) {\n    this.variableNames.push('preluActivationWeights');\n  }\n\n  if (hasLeakyReluAlpha) {\n    this.variableNames.push('leakyreluAlpha');\n  }\n\n  this.userCode = \"\\n      \".concat(activationSnippet, \"\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \").concat(channelMul, \";\\n        int q = d2 - d1 * \").concat(channelMul, \";\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\\n        vec4 dotProd = vec4(0.000000000000001);\\n\\n        \").concat(mainLoop, \"\\n\\n        vec4 result = dotProd - vec4(0.000000000000001);\\n        \").concat(addBiasSnippet, \"\\n        \").concat(applyActivationSnippet, \"\\n        setOutput(result);\\n      }\\n    \");\n};","map":{"version":3,"sources":["../../../../../tfjs-backend-webgl/src/conv_packed_gpu_depthwise.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAsB,IAAtB,QAAiC,uBAAjC;AAEA,SAAsB,gBAAtB,QAA6C,cAA7C;AAEA,WAAa,4BAAb,GAcE,sCACI,QADJ,EAG6B;AAAA,MAFU,OAEV,uEAFoB,KAEpB;AAAA,MADzB,UACyB,uEADJ,IACI;AAAA,MADE,kBACF,uEADuB,KACvB;AAAA,MAAzB,iBAAyB,uEAAL,KAAK;;AAAA;;AAhB7B,OAAA,aAAA,GAAgB,CAAC,GAAD,EAAM,GAAN,CAAhB;AACA,OAAA,YAAA,GAAe,IAAf;AACA,OAAA,YAAA,GAAe,IAAf;AAIA,OAAA,cAAA,GAAiB,CACf;AAAC,IAAA,IAAI,EAAE,MAAP;AAAe,IAAA,IAAI,EAAE;AAArB,GADe,EAEf;AAAC,IAAA,IAAI,EAAE,SAAP;AAAkB,IAAA,IAAI,EAAE;AAAxB,GAFe,EAGf;AAAC,IAAA,IAAI,EAAE,WAAP;AAAoB,IAAA,IAAI,EAAE;AAA1B,GAHe,EAIf;AAAC,IAAA,IAAI,EAAE,QAAP;AAAiB,IAAA,IAAI,EAAE;AAAvB,GAJe,CAAjB;AAWE,OAAK,WAAL,GAAmB,QAAQ,CAAC,QAA5B;AACA,OAAK,mBAAL,GAA2B,gBAAgB,CAAC,KAAK,WAAL,CAAiB,MAAlB,CAA3C;AACA,MAAM,UAAU,GAAG,QAAQ,CAAC,WAAT,GAAuB,QAAQ,CAAC,UAAnD;AACA,MAAM,OAAO,GAAG,QAAQ,CAAC,OAAT,CAAiB,IAAjC;AACA,MAAM,WAAW,GAAG,QAAQ,CAAC,WAA7B;AACA,MAAM,aAAa,GAAG,QAAQ,CAAC,aAA/B;AACA,MAAM,YAAY,GAAG,QAAQ,CAAC,YAA9B;AACA,MAAM,WAAW,GAAG,QAAQ,CAAC,WAA7B;AACA,MAAM,YAAY,GAAG,WAArB;AAEA,MAAI,QAAQ,yFAAZ;;AAIA,OAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,WAApB,EAAiC,CAAC,EAAlC,EAAsC;AACpC,IAAA,QAAQ,sCACU,CAAC,GAAG,CADd,qCAES,CAAC,GAAG,CAFb,2CAGU,CAAC,GAAG,CAAJ,GAAQ,CAHlB,qCAIS,CAAC,GAAG,CAAJ,GAAQ,CAJjB,sCAKK,CALL,MAAR;AAMD;AAED;;;;;;;AAOG;;;AACH,EAAA,QAAQ,wCACc,YADd,qBAAR;;AAGA,OAAK,IAAI,EAAC,GAAG,CAAb,EAAgB,EAAC,GAAG,WAApB,EAAiC,EAAC,EAAlC,EAAsC;AACpC,IAAA,QAAQ,iCACK,EAAC,GAAG,CADT,6CAEK,EAAC,GAAG,CAFT,0CAGK,EAAC,GAAG,CAAJ,GAAQ,CAHb,6CAIK,EAAC,GAAG,CAAJ,GAAQ,CAJb,qCAKA,EALA,kBAAR;AAMD;;AACD,EAAA,QAAQ,kGAAR;;AAKA,OAAK,IAAI,MAAM,GAAG,CAAlB,EAAqB,MAAM,GAAG,CAAC,YAAY,GAAG,CAAhB,IAAqB,CAAnD,EAAsD,MAAM,EAA5D,EAAgE;AAC9D,QAAM,QAAQ,GAAG,MAAM,GAAG,CAA1B;AAEA,IAAA,QAAQ,0CACc,QAAQ,GAAG,aADzB,kBAAR;;AAIA,QAAI,WAAW,KAAK,CAApB,EAAuB;AACrB,UAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B;AACA,YAAI,OAAO,GAAG,CAAV,KAAgB,CAApB,EAAuB;AACrB;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA,UAAA,QAAQ,wHAGJ,QAHI,qDAIO,QAJP,iQASS,QATT,6EAWO,QAXP,kDAAR,CAVqB,CAwBrB;AACA;;AACA,cAAI,aAAa,KAAK,CAAlB,IAAuB,QAAQ,GAAG,CAAtC,EAAyC;AACvC,YAAA,QAAQ,kCACF,QADE,4BACwB,QAAQ,GAAG,CADnC,yBAEJ,QAFI,4BAAR;AAID,WALD,MAKO;AACL,YAAA,QAAQ,sdAYE,QAZF,yCAYyC,QAZzC,sEAcE,QAdF,sCAcsC,QAdtC,mDAAR;AAiBD;AACF,SAlDD,MAkDO;AACL;AACA,UAAA,QAAQ,wEACsC,QADtC,qDAEO,QAFP,mHAIS,QAJT,6EAMO,QANP,gEASA,QATA,uBASqB,QATrB,wBAAR;AAWD;;AAED,YAAI,QAAQ,GAAG,CAAX,GAAe,WAAnB,EAAgC;AAC9B;AACA;AACA;AACA;AACA;AAEA,cAAM,eAAe,GAAG,OAAO,GAAG,CAAV,KAAgB,CAAhB,GACpB,IAAI,CAAC,iBAAL,CAAuB,aAAvB,CADoB,GAEpB,aAFJ;;AAIA,cAAK,aAAa,GAAG,CAAhB,KAAsB,CAAtB,IAA2B,OAAO,GAAG,CAAV,KAAgB,CAA5C,IACC,aAAa,GAAG,CAAhB,KAAsB,CAAtB,IAA2B,OAAO,GAAG,CAAV,KAAgB,CADhD,EACoD;AAClD,YAAA,QAAQ,qEACiC,eADjC,wFAIJ,QAAQ,GAAG,CAJP,uDAKO,QAAQ,GAAG,CALlB,yQAUS,QAAQ,GAAG,CAVpB,iFAYO,QAAQ,GAAG,CAZlB,wDAAR,CADkD,CAiBlD;AACA;;AACA,gBAAI,aAAa,GAAG,CAApB,EAAuB;AACrB,cAAA,QAAQ,4HAGJ,QAHI,yDAIO,QAJP,6EAKO,QALP,4DAAR;AAQD;;AAED,YAAA,QAAQ,oCACA,QAAQ,GAAG,CADX,4BAC8B,QAD9B,yBAEJ,QAAQ,GAAG,CAFP,8BAAR;AAID,WAnCD,MAmCO;AACL;AACA;AACA;AACA,gBAAI,eAAe,KAAK,CAAxB,EAA2B;AACzB,cAAA,QAAQ,sCACA,QAAQ,GAAG,CADX,uBACyB,QADzB,4BAAR;AAGD,aAJD,MAIO;AACL,cAAA,QAAQ,oDACc,eADd,0FAIJ,QAAQ,GAAG,CAJP,yDAKO,QAAQ,GAAG,CALlB,uIAOS,QAAQ,GAAG,CAPpB,qFASO,QAAQ,GAAG,CATlB,wEAYA,QAAQ,GAAG,CAZX,uBAYyB,QAAQ,GAAG,CAZpC,4BAAR;AAcD;AACF;AACF;AACF;AACF,KA7ID,MA6IO;AAAG;AACR,UAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAI,OAAO,GAAG,CAAV,KAAgB,CAApB,EAAuB;AACrB,UAAA,QAAQ,oIAGJ,QAHI,qDAIO,QAJP,+PAQS,QART,6EAUO,QAVP,6GAcJ,QAAQ,GAAG,CAdP,qDAeO,QAAQ,GAAG,CAflB,uPAmBS,QAAQ,GAAG,CAnBpB,6EAqBO,QAAQ,GAAG,CArBlB,gEAwBA,QAxBA,4BAwB0B,QAxB1B,yBAyBJ,QAAQ,GAAG,CAzBP,0BAAR;;AA4BA,cAAI,QAAQ,GAAG,CAAX,GAAe,WAAnB,EAAgC;AAC9B,YAAA,QAAQ,6QAMA,QAAQ,GAAG,CANX,4BAM8B,QAAQ,GAAG,CANzC,sCAAR;AAQD;AACF,SAvCD,MAuCO;AACL,UAAA,QAAQ,uEACqC,QADrC,qDAEO,QAFP,mHAIS,QAJT,6EAMO,QANP,8JAWJ,QAAQ,GAAG,CAXP,qDAYO,QAAQ,GAAG,CAZlB,+HAcS,QAAQ,GAAG,CAdpB,4EAgBO,QAAQ,GAAG,CAhBlB,gEAmBA,QAnBA,gDAoBO,QApBP,yBAoB8B,QAAQ,GAAG,CApBzC,0BAAR;;AAuBA,cAAI,QAAQ,GAAG,CAAX,GAAe,WAAnB,EAAgC;AAC9B,YAAA,QAAQ,oCACA,QAAQ,GAAG,CADX,4BAC8B,QAD9B,yBAEJ,QAAQ,GAAG,CAFP,4BAAR;AAID;AACF;AACF;AACF,KApO6D,CAsO9D;AACA;AACA;AACA;;;AACA,QAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B,MAAA,QAAQ,6CACe,QADf,iDAEW,QAFX,+CAAR;;AAKA,UAAI,QAAQ,GAAG,CAAX,GAAe,WAAnB,EAAgC;AAC9B,QAAA,QAAQ,+CACe,QAAQ,GAAG,CAD1B,mDAEW,QAAQ,GAAG,CAFtB,iDAAR;AAID;AACF;AACF;;AACD,EAAA,QAAQ,iBAAR;AAGA,EAAA,QAAQ,qBAAR;AAIA,MAAI,iBAAiB,GAAG,EAAxB;AAAA,MAA4B,sBAAsB,GAAG,EAArD;;AACA,MAAI,UAAJ,EAAgB;AACd,QAAI,kBAAJ,EAAwB;AACtB,MAAA,iBAAiB,8GAEb,UAFa,gBAAjB;AAID,KALD,MAKO,IAAI,iBAAJ,EAAuB;AAC5B,MAAA,iBAAiB,sGAEb,UAFa,gBAAjB;AAID,KALM,MAKA;AACL,MAAA,iBAAiB,kDACb,UADa,gBAAjB;AAGD;;AAED,IAAA,sBAAsB,iCAAtB;AACD;;AAED,MAAM,cAAc,GAAG,OAAO,GAAG,iCAAH,GAAuC,EAArE;;AACA,MAAI,OAAJ,EAAa;AACX,SAAK,aAAL,CAAmB,IAAnB,CAAwB,MAAxB;AACD;;AAED,MAAI,kBAAJ,EAAwB;AACtB,SAAK,aAAL,CAAmB,IAAnB,CAAwB,wBAAxB;AACD;;AACD,MAAI,iBAAJ,EAAuB;AACrB,SAAK,aAAL,CAAmB,IAAnB,CAAwB,gBAAxB;AACD;;AAED,OAAK,QAAL,qBACI,iBADJ,yNAQoB,UARpB,0CASwB,UATxB,4OAgBM,QAhBN,mFAmBM,cAnBN,uBAoBM,sBApBN;AAwBD,CAzXH","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\n\nimport {GPGPUProgram, useShapeUniforms} from './gpgpu_math';\n\nexport class DepthwiseConvPacked2DProgram implements GPGPUProgram {\n  variableNames = ['x', 'W'];\n  packedInputs = true;\n  packedOutput = true;\n  outputShape: number[];\n  userCode: string;\n  enableShapeUniforms: boolean;\n  customUniforms = [\n    {name: 'pads', type: 'ivec2' as const },\n    {name: 'strides', type: 'ivec2' as const },\n    {name: 'dilations', type: 'ivec2' as const },\n    {name: 'inDims', type: 'ivec2' as const },\n  ];\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: string = null, hasPreluActivation = false,\n      hasLeakyReluAlpha = false) {\n    this.outputShape = convInfo.outShape;\n    this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);\n    const channelMul = convInfo.outChannels / convInfo.inChannels;\n    const padLeft = convInfo.padInfo.left;\n    const strideWidth = convInfo.strideWidth;\n    const dilationWidth = convInfo.dilationWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const texelsAcross = filterWidth;\n\n    let mainLoop = `\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;`;\n\n    for (let c = 0; c < filterWidth; c++) {\n      mainLoop += `\n          vec4 xTexelC${c * 2};\n          int xTexelC${c * 2}Ready;\n          vec4 xTexelC${c * 2 + 1};\n          int xTexelC${c * 2 + 1}Ready;\n          vec4 xC${c};`;\n    }\n\n    /**\n     * This vectorized implementation works by gathering the values needed for\n     * each output channel's dot product into vec4's and then multiplying them\n     * all together (this happens in the final double for-loop below). Most of\n     * the main loop consists of constructing these vec4's with the minimum\n     * number of texture2D calls, which means making use of all four returned\n     * values from a texture2D call at once.\n     */\n    mainLoop += `\n    for (int r = 0; r < ${filterHeight}; r++) {\n      `;\n    for (let c = 0; c < filterWidth; c++) {\n      mainLoop += `\n          xTexelC${c * 2} = vec4(0.0);\n          xTexelC${c * 2}Ready = 0;\n          xTexelC${c * 2 + 1} = vec4(0.0);\n          xTexelC${c * 2 + 1}Ready = 0;\n          xC${c} = vec4(0.0);`;\n    }\n    mainLoop += `\n        xR = xRCorner + r * dilations[0];\n        if (xR >=0 && xR < inDims[0]) {\n      `;\n\n    for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n      const colIndex = texelC * 2;\n\n      mainLoop += `\n          xC = xCCorner + ${colIndex * dilationWidth};\n          `;\n\n      if (strideWidth === 1) {\n        if (colIndex < filterWidth) {\n          // If padding is odd, the outer texels have to be composed.\n          if (padLeft % 2 === 1) {\n            // TODO: Ensure vec4 previous does not result in redundant sample,\n            // and avoid setting xTexelRC's that exceed the boundary in the\n            // first place rather than resetting them to vec4(0)).\n\n            // To compute xCOffset:\n            // - If padding is odd, we must add 1 to ensure we ask for an\n            // even-numbered row.\n            // - We subtract 2 to access the previous texel.\n\n            mainLoop += `\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n              `;\n            // This texel has been read in previous iteration if the dilation\n            // is 1.\n            if (dilationWidth === 1 && colIndex > 0) {\n              mainLoop += `\n                xC${colIndex} = vec4(xTexelC${colIndex - 2}.zw, xTexelC${\n                  colIndex}.xy);\n                `;\n            } else {\n              mainLoop += `\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${colIndex} = vec4(previous.zw, xTexelC${colIndex}.xy);\n                  } else {\n                    xC${colIndex} = vec4(0.0, 0.0, xTexelC${colIndex}.xy);\n                  }\n                  `;\n            }\n          } else {\n            // Padding is even, so xRC corresponds to a single texel.\n            mainLoop += `\n                if (xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n\n                xC${colIndex} = xTexelC${colIndex};\n                `;\n          }\n\n          if (colIndex + 1 < filterWidth) {\n            // If dilation is even, the second entry should match the first\n            // (either both are composed or both are single samples). But if\n            // dilation is odd, then the second entry should be the opposite\n            // of the first (if the first is composed, the second is a single\n            // sample, and vice versa.)\n\n            const nextTexelOffset = padLeft % 2 === 0 ?\n                util.nearestLargerEven(dilationWidth) :\n                dilationWidth;\n\n            if ((dilationWidth % 2 === 0 && padLeft % 2 === 1) ||\n                (dilationWidth % 2 !== 0 && padLeft % 2 !== 1)) {\n              mainLoop += `\n                  xCOffset = xC + imod(pads[1], 2) + ${nextTexelOffset};\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                  colIndex + 1}Ready == 0) {\n                    xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      xTexelC${colIndex + 1}.zw = vec2(0.0);\n                    }\n                    xTexelC${colIndex + 1}Ready = 1;\n                  }\n                  `;\n\n              // If dilation > 1 then the xRC's will not be able to share any\n              // values, so each xRC will require two unique calls to getX.\n              if (dilationWidth > 1) {\n                mainLoop += `\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                    colIndex}Ready == 0) {\n                      xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n                      xTexelC${colIndex}Ready = 1;\n                    }\n                    `;\n              }\n\n              mainLoop += `\n                  xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${\n                  colIndex + 1}.xy);\n                  `;\n            } else {\n              // If dilation is 1 and padding is odd, we have already read the\n              // texel when constructing the previous x value. Here we can\n              // simply skip the texture read.\n              if (nextTexelOffset === 1) {\n                mainLoop += `\n                    xC${colIndex + 1} = xTexelC${colIndex};\n                    `;\n              } else {\n                mainLoop += `\n                    xCOffset = xC + ${nextTexelOffset};\n\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                    colIndex + 1}Ready == 0) {\n                      xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= inDims[1]) {\n                        xTexelC${colIndex + 1}.zw = vec2(0.0);\n                      }\n                      xTexelC${colIndex + 1}Ready = 1;\n                    }\n\n                    xC${colIndex + 1} = xTexelC${colIndex + 1};\n                    `;\n              }\n            }\n          }\n        }\n      } else {  // stride === 2\n        if (colIndex < filterWidth) {\n          // Depending on whether padLeft is even or odd, we want either the\n          // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n          // even, xC${colIndex +1} is simply the zw channels of texels we've\n          // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n          // need to come from the xy channels of a new texel, hence the `\n          // vec4\n          // final` initialized below.\n          if (padLeft % 2 === 1) {\n            mainLoop += `\n                xCOffset = xC + 1 - strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${\n                colIndex + 1}Ready == 0) {\n                  xTexelC${colIndex + 1} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= inDims[1]) {\n                    xTexelC${colIndex + 1}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex + 1}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(xTexelC${colIndex}.zw, xTexelC${\n                colIndex + 1}.zw);\n              `;\n\n            if (colIndex + 1 < filterWidth) {\n              mainLoop += `\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + strides[1];\n                  if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${colIndex + 1} = vec4(xTexelC${colIndex + 1}.xy, final.xy);\n                `;\n            }\n          } else {\n            mainLoop += `\n                if(xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n\n                xCOffset = xC + strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                colIndex + 1}Ready == 0) {\n                  xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${colIndex + 1}.zw = vec2(0.);\n                  }\n                  xTexelC${colIndex + 1}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(\n                  xTexelC${colIndex}.xy, xTexelC${colIndex + 1}.xy);\n              `;\n\n            if (colIndex + 1 < filterWidth) {\n              mainLoop += `\n                  xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${\n                  colIndex + 1}.zw);\n                `;\n            }\n          }\n        }\n      }\n\n      // localize the dotProd accumulation within the loop, the theory is for\n      // GPU with limited cache, accumulate sum across large amount of\n      // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n      // 50 variables)\n      if (colIndex < filterWidth) {\n        mainLoop += `\n            wTexel = getW(r, ${colIndex}, d1, q);\n            dotProd += xC${colIndex} * vec4(wTexel.xz, wTexel.xz);\n          `;\n\n        if (colIndex + 1 < filterWidth) {\n          mainLoop += `\n              wTexel = getW(r, ${colIndex + 1}, d1, q);\n              dotProd += xC${colIndex + 1} * vec4(wTexel.xz, wTexel.xz);\n            `;\n        }\n      }\n    }\n    mainLoop += `\n    }\n  `;\n    mainLoop += `\n      }\n    `;\n\n    let activationSnippet = '', applyActivationSnippet = '';\n    if (activation) {\n      if (hasPreluActivation) {\n        activationSnippet = `vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`;\n      } else if (hasLeakyReluAlpha) {\n        activationSnippet = `vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`;\n      } else {\n        activationSnippet = `vec4 activation(vec4 x) {\n          ${activation}\n        }`;\n      }\n\n      applyActivationSnippet = `result = activation(result);`;\n    }\n\n    const addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n    if (hasLeakyReluAlpha) {\n      this.variableNames.push('leakyreluAlpha');\n    }\n\n    this.userCode = `\n      ${activationSnippet}\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${channelMul};\n        int q = d2 - d1 * ${channelMul};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${mainLoop}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `;\n  }\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}